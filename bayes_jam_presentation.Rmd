---
title: "Welcome to the Bayes Jam"
subtitle: "QSC 2021"
author: "Nick Klagge, Andrew Nguyen"
institute: "FRB NY, Board of Governors"
output:
  xaringan::moon_reader:
    css: ["default", "custom.css"]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      beforeInit: "macros.js"
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
library(ggplot2)
library(dplyr)
library(tidyr)
library(purrr)
library(stringr)
library(MASS)
library(gt)
library(patchwork)
library(broom)

po_dat_long_high_seed_only <- readRDS('data/po_dat_long_high_seed_only.rds')
po_dat_long <- readRDS('data/po_dat_long.rds')
po_dat_wide <- readRDS('data/po_dat_wide.rds')

# prior probability distribution of series_win computed from negative binomial and game 1 p_win
# increase game win probability by 9% to align distribution mean with empirical series win freq
po_dat_wide <- po_dat_wide %>%
  mutate(prior_p_series_win = pnbinom(3,4,p_win_game_1*1.09))

```
## Disclaimer

* We started this project to learn something about Bayesian analysis with a fun topic
* We are by no means experts!
* If the Federal Reserve System has views on the NBA, this does not represent them

---

## Intro

* NBA playoffs are played in 'best of seven' series
   * Teams are matched up by "seed" or rank - 1 plays 8, 2 plays 7, and so on
   * Each series is best-of-seven. First team to win four games advances
   * Higher seeded team gets "home-court advantage"
   * Standard (mostly) pattern of H-H-A-A-H-A-H
   
* Some questions
   * Is there any game that is particularly important for winning a series?
   * How important is home-court advantage?

.center[
![:scale 50%](https://images.daznservices.com/di/library/sporting_news/e5/2f/nba-playoff-bracket-081720-ftr_m4cqpiv4n9fb1m1kkfqz411ok.jpg?t=27066196&w=500&quality=80)
]
---
## Data

* The outcome of every playoff game from 1998-2020 from [basketballreference.com](https://github.com/jaebradley/basketball_reference_web_scraper), scraped with Python
* Elo rating data from [538](https://projects.fivethirtyeight.com/complete-history-of-the-nba/#bucks), from R *fivethirtyeightdata* package
   * A relative ranking system updated after every game, originally developed for chess. Can be used to infer the probability of winning a single game
> " Two players with equal ratings who play against each other are expected to score an equal number of wins. A player whose rating is 100 points greater than their opponent's is expected to score 64%; if the difference is 200 points, then the expected score for the stronger player is 76%."

---

## Analysis framework

* Analyze all playoff series from the perspective of the higher seeded team
   * Want to be consistent when considering which games matter, given standardized home-away pattern
* Examine Elo, home court advantage, individual game influence
* We'll look at summary statistics, logit regression, and Bayesian estimation
* We focus most on games 1-4, as these are played in every series
  * Analyzing games 5-7 is tricky because their existence is conditional on earlier game outcomes
  * Games 1-4 have a fully consistent home/away pattern, while games 5 and 6 have differed at times

---

## High Level facts

* Elo implies that the higher seeded team should win individual games 58% of the time on average
* In fact, they win about 62% of games 
* This is largely explained by home court advantage: win frequency varies a lot by game number
* Higher seeded teams win about 75% of series ("best-of" favors the better team)
```{r}
po_dat_long_high_seed_only %>%
  group_by(is_home_team, game_num) %>%
  summarize(p_win = mean(win, na.rm=T)) %>%
  pivot_wider(names_from = is_home_team, values_from = p_win) %>%
  arrange(game_num) %>%
  magrittr::set_colnames(c('game_number', 'away_win_pcnt', 'home_win_pcnt')) %>%
  gt() %>%
  fmt_missing(everything()) %>%
  fmt_number(c('away_win_pcnt', 'home_win_pcnt'))
```

---

### Game 2 outcome most highly correlated with subsequent game outcomes
.center[
```{r}
prepender <- function(string, prefix = "Game ") paste0(prefix, string)

#don't filter on series length but plot by number of games played
#focus on first three games

plot_series_correlation <- function(data, n_games_played){
   data %>%
    filter(game_num <= n_games_played) %>%
    group_by(series, season, team) %>%
    arrange(series, season, team) %>%
    mutate(won_game_n = last(win)) %>%
    filter(won_game_n) %>%
    group_by(game_num) %>%
    summarise(prop = sum(win)/n()) %>%
   mutate(is_g2 = game_num == 2) %>%
    ggplot(aes(x = game_num, y = prop, fill = is_g2)) +
    geom_bar(stat = "identity", position = "dodge") +
    scale_x_continuous(breaks = 1:n_games_played) +
    guides(fill = "none") +
    ylab('Proportion of games won') +
    xlab('Game') +
    scale_fill_manual(values = c('TRUE' = 'blue', 'FALSE' = 'grey')) 

}

g2_plot <- po_dat_long_high_seed_only %>%
  plot_series_correlation(2) 

g3_plot <- po_dat_long_high_seed_only %>%
  plot_series_correlation(3) 

g4_plot <- po_dat_long_high_seed_only %>%
  plot_series_correlation(4) 
  
g5_plot <- po_dat_long_high_seed_only %>%
  plot_series_correlation(5)

g6_plot <- po_dat_long_high_seed_only %>%
  plot_series_correlation(6)

g7_plot <- po_dat_long_high_seed_only %>%
  plot_series_correlation(7)

g2_plot + g3_plot + g4_plot + g5_plot + g6_plot + g7_plot + plot_layout(nrow = 2)

```
]

---

### Game 2 outcome most highly correlated with winning the whole series
.pull-left[
```{r}
po_dat_wide %>%
   glm(data= ., won_series ~ win_game_1 + win_game_2 + win_game_3, family = 'binomial') %>%
   tidy() %>%
  dplyr::select(-statistic) %>%
   gt %>%
   fmt_number(-term) 
```
]

.pull-right[
```{r}
po_dat_wide %>%
   glm(data= ., won_series ~ win_game_1 + win_game_2 + win_game_3 + p_win_game_1, family = 'binomial') %>%
   tidy() %>%
  dplyr::select(-statistic) %>%
   gt %>%
   fmt_number(-term)

```
]
---
### Home court advantage still matters if we account for Elo
```{r}
#  - about 238 Elo points
glm(win ~ elo_diff + is_home_team, data = po_dat_long_high_seed_only, family="binomial") %>%
   tidy() %>%
   gt %>%
   fmt_number(-term)

```

---
### "I know I am just an algorithm... No one knows who I am, or what I do. But that all changes today." 
Al G Rhythm on Bayesian updating
.center[
![](https://c.tenor.com/36LrUnJooEMAAAAC/hmm-alg-rhythm.gif)]
---
## A Bayesian perspective

* Bayesian reasoning focuses on taking existing probability estimates and updating them based on new information
* This seems like a natural framework for our questions: we're interested in how the serial outcomes of individual games influence the probability of an overall series win
* Let's start by assuming we don't know anything about the two teams playing in a given series besides which one is higher-seeded. How estimate of their series win probability?
  * In a "frequentist" perspective, we could estimate their win probability by the sample average series win frequency for higher-seeded teams: 75%
  * In reality, we know that there's not just a single answer to this question: some series are very closely matched and others are not
  * That 75% sample average is made up of a range of higher and lower individual win probabilities
  * Bayesian reasoning lets us represent our estimate of the win probability with a probability distribution

---

## The beta distribution

We let the higher-seeded team's series win probability $p$ be described by a beta distribution. why?

* Bounded between 0,1
* Extremely flexible with only two parameters
* Estimate $\alpha$ and $\beta$ (more on these in a second)

$$\operatorname{E}[X] = \frac{\alpha}{\alpha+\beta}$$

.center[
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/f/f3/Beta_distribution_pdf.svg/1920px-Beta_distribution_pdf.svg.png" width="400" height="300" />
]


---

## Developing a prior

* What is our "prior" estimate of the distribution of win probability, before observing any game outcomes?
* The most "uninformed" prior would be a beta(1,1), which is equivalent to the uniform distribution
* But we definitely know at least a little more than that: at minimum, we know the home team is more likely to win (both because they are higher ranked and because of home court advantage)
* We can use the pre-series Elo ratings and the negative binomial distribution to develop our prior

---

## The negative binomial distribution

The negative binomial distribution is based on an experiment satisfying the following conditions:

1. The experiment consists of a sequence of independent trials.
2. Each trial can result in either a success or a failure.
3. The probability of success $p$ is constant from trial to trial
4. The experiment continues until a total of $r$ successes have been observed

.center[
<img src="https://www.statisticshowto.com/wp-content/uploads/2015/04/negative-bimonial.png" width="350" height="250" />
]

This sounds a lot like the conditions of a best-of-seven series! 

---

## Negative binomial series win probabilities

* Given any two teams' pre-series Elo ratings, we can calculate the game-wise win probability, and feed this to the negative binomial distribution to estimate the series-wise win probability.
* We know that the assumptions of the negative binomial don't fully hold in the NBA playoffs: home-court advantage means that the win probability varies in different game numbers. But maybe it's close enough to develop a reasonable prior
* We estimated the win probabilities for each series in the dataset using Elo and the negative binomial, then fit a beta distribution to that sample
* We found that the mean of this distribution was slightly lower than the empirical win frequency for the higher seeded team
  * This makes sense because the negative binomial does not account for home court advantage
  * We adjust the game-level win probability upward to approximate this. We find that a 9% increase in the higher-seeded team's game-level win probability results in a distribution with a mean that matches the empirical frequency.

---

### Our prior on series win probability

```{r, echo = TRUE, results = 'hide'}
beta_fit <- MASS::fitdistr(po_dat_wide$prior_p_series_win, dbeta,
                    start = list(shape1 = 1, shape2 = 1))
# beta estimates: 3.86, 1.24
alpha0 <- beta_fit$estimate[1]
beta0 <- beta_fit$estimate[2]
# mean p(series_win) is 76%
alpha0/(alpha0+beta0)
```

.center[
```{r, out.width="40%", out.height='40%'}
# plot
ggplot(po_dat_wide) +
  geom_histogram(aes(prior_p_series_win, y = ..density..), binwidth = .05) +
  stat_function(fun = function(x) dbeta(x, alpha0, beta0), color = "red",
                size = 1) +
  xlab("Series win probability")
```
]

---
## Updating the prior

* The beta distribution has the special property of being a *conjugate prior* for Bernoulli trials
* This means that, when we have a beta-distributed prior on a binomial probability, then observe a sample of Bernoulli trials, the posterior distribution after we update on the outcomes is also a beta distribution

In particular, when we observe new successes and failures, the new Beta distribution becomes

$$Beta(\alpha_0+successes,\beta_0+failures)$$

In a basketball playoff context, say we observe $n$ series and in $m$ of those, the teams won game 1 and the series. We can update our prior accordingly 

$$Beta(\alpha_0+m,\beta_0+(n-m))$$

---

### Update conditional on game 1 win

.center[
```{r}
cond <- sum(po_dat_wide$win_game_1)
ws_cond <- sum(po_dat_wide$win_game_1 & po_dat_wide$won_series)
alpha1 <- alpha0 + ws_cond
beta1 <- beta0 + (cond - ws_cond)

ggplot() +
  stat_function(fun = function(x) dbeta(x, alpha0, beta0), aes(color = "line1"),
                size = 1) +
  stat_function(fun = function(x) dbeta(x, alpha1, beta1), aes(colour = "line2"),
                size = 1) +
  xlab("Series win probability") +
  scale_colour_manual(
  values = c('black', 'blue'),
  labels = c('Initial Estimate (Prior)', 'Estimate after winning game 1 (Posterior)')) + 
   guides(color = guide_legend(title = "")) 
```
]

---
### Update conditional on game 2 win

.center[
```{r}
# update: won game 2 (conditional series win prob: 84%)
cond <- sum(po_dat_wide$win_game_2)
ws_cond <- sum(po_dat_wide$win_game_2 & po_dat_wide$won_series)
alpha2 <- alpha0 + ws_cond
beta2 <- beta0 + (cond - ws_cond)

ggplot() +
  stat_function(fun = function(x) dbeta(x, alpha0, beta0), aes(color = "line1"),
                size = 1) +
  stat_function(fun = function(x) dbeta(x, alpha2, beta2), aes(colour = "line2"),
                size = 1) +
  xlab("Series win probability") +
  scale_colour_manual(
  values = c('black', 'red'),
  labels = c('Initial Estimate (Prior)', 'Estimate after winning game 2 (Posterior)')) + 
   guides(color = guide_legend(title = "")) 
```
]
---

### Update conditional on winning each of first four games

.center[
```{r}
# update: won game 3 (conditional series win prob: 91%)
cond <- sum(po_dat_wide$win_game_3)
ws_cond <- sum(po_dat_wide$win_game_3 & po_dat_wide$won_series)
alpha3 <- alpha0 + ws_cond
beta3 <- beta0 + (cond - ws_cond)

cond <- sum(po_dat_wide$win_game_4)
ws_cond <- sum(po_dat_wide$win_game_4 & po_dat_wide$won_series)
alpha4 <- alpha0 + ws_cond
beta4 <- beta0 + (cond - ws_cond)

ggplot() +
  stat_function(fun = function(x) dbeta(x, alpha1, beta1), aes(color = "w1"),
                size = 1) +
  stat_function(fun = function(x) dbeta(x, alpha2, beta2), aes(color = "w2"),
                size = 1) +
  stat_function(fun = function(x) dbeta(x, alpha3, beta3), aes(color = "w3"),
                size = 1) +
  stat_function(fun = function(x) dbeta(x, alpha4, beta4), aes(color = "w4"),
                size = 1) +
  xlab("Series win probability") +
  scale_colour_manual(
  values = c('w1' = 'red', 'w2' = 'blue', 'w3' = 'green', 'w4' = 'purple'),
  labels = c('Estimate after winning game 1', 'Estimate after winning game 2', 'Estimate after winning game 3', 'Estimate after winning game 4')) + 
   guides(color = guide_legend(title = ""))
```
]

---

### Update after losing game 1

.center[
```{r}
# update: lost game 1 (conditional series win prob: 54%)
cond <- sum(!po_dat_wide$win_game_1)
ws_cond <- sum(!po_dat_wide$win_game_1 & po_dat_wide$won_series)
alpha1l <- alpha0 + ws_cond
beta1l <- beta0 + (cond - ws_cond)

ggplot() +
  stat_function(fun = function(x) dbeta(x, alpha0, beta0), aes(color = "black"),
                size = 1) +
  stat_function(fun = function(x) dbeta(x, alpha1, beta1), aes(color = "blue"),
                size = 1) +
  stat_function(fun = function(x) dbeta(x, alpha1l, beta1l), aes(color = "green"),
                size = 1) +
  xlab("Series win probability") +
  scale_colour_manual(
  values = c('black', 'blue', 'green'),
  labels = c('Initial Estimate', 'Estimate after winning game 1', 'Estimate after losing game 1')) + 
   guides(color = guide_legend(title = "")) 

```
]

---

### Condition on a winning path

.center[
```{r}
# update: WL (conditional series win prob: 60%)
cond <- sum(po_dat_wide$win_game_1 & !po_dat_wide$win_game_2)
ws_cond <- sum(po_dat_wide$win_game_1 & !po_dat_wide$win_game_2 & po_dat_wide$won_series)
alphaWL <- alpha0 + ws_cond
betaWL <- beta0 + (cond - ws_cond)

# update: LW (conditional series win prob: 65%)
cond <- sum(!po_dat_wide$win_game_1 & po_dat_wide$win_game_2)
ws_cond <- sum(!po_dat_wide$win_game_1 & po_dat_wide$win_game_2 & po_dat_wide$won_series)
alphaLW <- alpha0 + ws_cond
betaLW <- beta0 + (cond - ws_cond)

# update: WW (conditional series win prob: 92%)
cond <- sum(po_dat_wide$win_game_1 & po_dat_wide$win_game_2)
ws_cond <- sum(po_dat_wide$win_game_1 & po_dat_wide$win_game_2 & po_dat_wide$won_series)
alphaWW <- alpha0 + ws_cond
betaWW <- beta0 + (cond - ws_cond)


# update: LL (conditional series win prob: 13%)
cond <- sum(!po_dat_wide$win_game_1 & !po_dat_wide$win_game_2)
ws_cond <- sum(!po_dat_wide$win_game_1 & !po_dat_wide$win_game_2 & po_dat_wide$won_series)
alphaLL <- alpha0 + ws_cond
betaLL <- beta0 + (cond - ws_cond)

ggplot() +
  stat_function(fun = function(x) dbeta(x, alpha0, beta0), aes(color = "base"),
                size = 1) +
  stat_function(fun = function(x) dbeta(x, alphaWL, betaWL), aes(color = "wl"),
                size = 1) +
  stat_function(fun = function(x) dbeta(x, alphaLW, betaLW), aes(color = "lw"),
                size = 1) +
  stat_function(fun = function(x) dbeta(x, alphaWW, betaWW), aes(color = "ww"),
                size = 1) +
  stat_function(fun = function(x) dbeta(x, alphaLL, betaLL), aes(color = "ll"),
                size = 1) +
  xlab("Series win probability")  +
  scale_colour_manual(
  values = c('base' = 'black', 'wl' = 'red', 'lw' = 'blue', 'ww' = 'green', 'll' = 'purple'),
  labels = c('Initial Estimate', 'WL', 'LW', 'WW', 'LL')) + 
   guides(color = guide_legend(title = "Win Path")) 

```

]

---

## Estimate differences in means



```{r}

sim_LW <- rbeta(10000, alphaLW, betaLW)
sim_WL <- rbeta(10000, alphaWL, betaWL)
sim_diff <- sim_LW - sim_WL
df_sd <- tibble(sim_diff)

norm_fit <- MASS::fitdistr(df_sd$sim_diff, "normal")
ggplot(df_sd) +
  geom_histogram(aes(sim_diff, y = ..density..), binwidth = .01) +
  stat_function(fun = function(x) dnorm(x, norm_fit$estimate[1], norm_fit$estimate[2]), color = "red",
                size = 1) +
  xlab("Simulated prob difference: LW minus WL")
```


---

# Takeaways

* Game 2 looks like the most influential game, but we need more playoff data to say this with  confidence!
* Bayesian thinking lends itself well to cases like playoffs where an uncertain outcome is determined by a series of events that happen over time
* It's very easy to update beta priors with Bernoulli trial outcomes
* Posteriors help visualize how uncertainty decreases as well as how mean estimate changes

---

# References

* [Understanding empirical Bayes estimation (using baseball statistics) by David Robinson](http://varianceexplained.org/r/empirical_bayes_baseball/)
* [ELO Rating System](https://en.wikipedia.org/wiki/Elo_rating_system)