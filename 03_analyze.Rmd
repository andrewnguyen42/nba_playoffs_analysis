---
title: ''
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(ggplot2)
#library(gamlss)
library(dplyr)
library(tidyr)

po_dat_long <- readRDS('data/po_dat_long.rds')
po_dat_wide <- readRDS('data/po_dat_wide.rds')

result <- 3

```

# Background

An NBA playoff series is a set of games played until one team wins four games. The maximum number of games in a series is seven since both teams could win three games apiece and the seventh game is the series-deciding game. We refer to this structure as a "best of seven series." In this presentation, we'll be modeling the impact of winning a single game on the overall probability of winning a series. We'll also examine how we can approach this model a frequentist and Bayesian perspective.

this is my result `r result`

# Data Exploration

Before building any models, let's look at the how a playoff series evolves. Interestingly, game 2 is the most correlated with winning a series than any game (besides the deciding game, of course). For a series that lasts 5 games, the team that won game 2 won the series roughly 90% of the time. For a series that lasts 6 games, the team that won game 2 won the series about 65% of the time. 

```{r}
prepender <- function(string, prefix = "Game ") paste0(prefix, string)

plot_series_correlation <- function(data, n_games_series){
  data %>%
    filter(series_length == n_games_series, win, name == 'home_team') %>%
    ggplot(aes(x = win, fill = won_series, group = won_series)) +
    geom_bar(position = "fill") +
    facet_wrap(vars(game_num), nrow = 1, labeller = as_labeller(prepender)) +
    theme(axis.title.x=element_blank(),
          axis.text.x=element_blank(),
          axis.ticks.x=element_blank()) +
    guides(fill = "none") +
    ylab('Proportion of series won') +
    scale_fill_manual(values = c('TRUE' = 'blue', 'FALSE' = 'NA'))
}


po_dat_long %>%
  plot_series_correlation(4)

po_dat_long %>%
  plot_series_correlation(5)

po_dat_long %>%
  plot_series_correlation(6)

po_dat_long %>%
  plot_series_correlation(7)

```
# Linear Probability Model - First Pass

We can model a playoff series with a linear model where we predict the outcome of a series and include indicator functions for whether a game was won or lost.

$$winSeries = \beta_0 + \Sigma_{i=1}^6 \beta_iWonGame_i + \epsilon  $$
Our first-pass model again tells us that winning game 2 has the greatest marginal effect of winning a series. The issue with this model is that a lot of series end before 6 games have been played, and any playoff series with fewer than 6 games will get thrown out of our regression.

```{r}
#basic linear probability

po_dat_wide %>%
  lm(data= ., won_series ~ win_game_1 + win_game_2 + win_game_3 + win_game_4 + win_game_5 + win_game_6) %>%
  broom::tidy() 
```

For the next pass of the model, we restrict the sample to 4, 5, 6 and 7 game series and estimate separate regressions for each of those series lengths. We run into estimation problems galore with this approach. For a 4 game series, winning any single game means the series is already decided. And for a 5 game series, once we know the first 4 games and know that the series is 5 games long, we know perfectly well which team will win the series.

```{r}
po_dat_wide %>%
  filter(series_length == 4) %>%
  lm(data= ., won_series ~ win_game_1 + win_game_2 + win_game_3 + p_win_game_1) %>%
  broom::tidy() 


po_dat_wide %>%
  filter(series_length == 5) %>%
  lm(data= ., won_series ~  win_game_1 + win_game_2 + win_game_3  + p_win_game_1) %>%
  broom::tidy() 
  
po_dat_wide %>%
  filter(series_length == 6) %>%
  lm(data= ., won_series ~ win_game_1 + win_game_2 + win_game_3 + win_game_4 + p_win_game_1) %>%
  broom::tidy() 


po_dat_wide %>%
  filter(series_length == 7) %>%
  lm(data= ., won_series ~ win_game_1 + win_game_2 + win_game_3 + win_game_4 + win_game_5  + p_win_game_1) %>%
  broom::tidy() 
```

There is probably a more clever regression framework that would help explain us examine playoff series, but a Bayesian analysis sidesteps many of our previous issues.


# Reframing the Problem

The negative binomial distribution is based on an experiment satisfying the following conditions:

1. The experiment consists of a sequence of independent trials.
2. Each trial can result in either a success or a failure.
3. The probability of success $p$ is constant from trial to trial
4. The experiment continues until a total of $r$ successes have been observed

$$    nb(k; r, p) \equiv \Pr(X = k) = \binom{k+r-1}{r-1} (1-p)^kp^r$$

Consider nb(n = 4; r = 7, p = .5) = P(X = 3), the probability that exactly 3 losses occur before the 7th game and your probability of winning each game is 50%.

`pnbinom(3, 7, .5) = .2744 `

We should think about our problem as a negative binomial distribution. Given $k$ remaining games in the series, what is the likelihood that you win $r$ games? 

```{r}

n_games <- 6
games_played <- 2

game7_series <- po_dat_wide %>%
  filter(series_length == n_games) %>% select_if(~sum(!is.na(.)) > 0)

win_col_names <- grep("^win_game_", names(game7_series), value = TRUE)[1:games_played]

form <- reformulate(c(win_col_names, 'p_win_game_1'), response = "won_series")

game_2_model <- gamlss::gamlss(form
               , data = game7_series
               , link = BNB())
mu_coefs <- game_2_model$mu.coefficients
mu_coefs
game_2_model$sigma.coefficients


lm_model <- po_dat_wide %>%
  filter(series_length == 6) %>%
  lm(data = ., won_series ~  win_game_1 + win_game_2  + p_win_game_1) 


predict_data <- expand.grid(replicate(games_played, c(TRUE, FALSE), simplify = FALSE)) %>%
  magrittr::set_colnames(win_col_names) %>%
  unite(col = id, everything(), remove = FALSE) %>%
  mutate(id = reduce2(c('TRUE', 'FALSE', '_'), c('W', 'L', ''),  .init = id, str_replace_all)
         , n_wins = str_count(id, pattern = "W")
         , p_win_game_1 = .5)

fitted_distributions <- predict_data %>%
  mutate(fitted = predict(game_2_model, newdata = predict_data %>% select(-id, -n_wins))
         , fitted_lm = predict(lm_model, predict_data %>% select(-id))) %>%
  mutate(sigma = exp(game_2_model$sigma.coefficients)
         , alpha = fitted/sigma
         , beta = (1-fitted)/sigma
         , posterior_probability = pnbinom(q = 4 - n_wins, size = 7 - games_played, prob = fitted) ) 

#how prior distribution of win probability changes
fitted_distributions %>%
  crossing(x = seq(.01, .99, length.out = 100)) %>%
  mutate(prior_density = dbeta(x, alpha, beta)) %>%
  ggplot(aes(x = x, y = prior_density, colour = id)) +
  geom_line()

```
